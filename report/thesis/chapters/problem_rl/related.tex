Bài toán huấn luyện mô hình học tăng cường bằng cách tối ưu hóa mạng policy là một hướng nghiên cứu mới trong thời gian gần đây. Mặc dù việc xác định kết quả đầu ra trong mô hình học tăng cường hay tổng phần thưởng thu được với một policy cho trước sau một khoảng thời gian là khó khăn vì liên quan đến các yếu tố ngẫu nhiên. Bằng kết quả ước lượng thu được này các nhà nghiên cứu trước đây sử dụng các phương pháp liên quan đến gradient \cite{jansen2015analyzing} để cập nhật lại các tham số của mô hình. Tuy nhiên, việc nghĩ đến một giải pháp nào đó hoàn toàn độc lập với các phương pháp gradient thông thường mới được đưa ra vào năm 2018 bởi nhóm nghiên cứu Uber AI \cite{such2017deep}. Phương pháp được đưa ra đó là sử dụng EA để huấn luyện các mạng ANN nhiều lớp để giải bài toán học tăng cường. Việc EA có thể huấn luyện được các mạng ANN không có nghĩa là EA sẽ có thể hoàn toàn thay thế được các phương pháp gradient mà với cụ thể với những bài toán học tăng cường với nhiều yếu tố ngẫu nhiên, EA đã chứng minh độ hiệu quả. 

Mặc dù vậy, khi một bài toán học tăng cường việc môi trường của trò chơi thay đổi, các lời giải đã học trước đó sẽ trở nên vô nghĩa. Để giải quyết thách thức này, một số nhóm nghiên cứu đã bắt đầu tận dụng khả năng của tiến hóa đa nhiệm (MFEA-I) để giải nhiều mô hình học tăng cường đồng thời với các tham số môi trường khác nhau. Tuy nhiên hướng đi này gặp phải cản trở bởi hạn chế của phương pháp MFEA-I khi không không thể điều khiển mức độ trao đổi giữa các tác vụ khác nhau. 

Trong đồ án này bằng ý tưởng huấn luyện nhiều mạng neural đã trình bày ở chương 3 kết hợp với những nghiên cứu về các phương pháp huấn luyện mô hình học tăng cường bằng phương pháp tiến hóa trước đó \cite{such2017deep}, Đồ án sẽ đề xuất phương pháp áp dụng tiến hóa đa nhiệm với ước lượng hệ số trao đổi trực tuyến (MFEA-II) để huấn luyện mô hình học tăng cường với môi trường khác nhau. Với sự thay đổi để giải quyết vấn đề trong phiên bản tiến hóa đa nhiệm trước đó, MFEA-II có khả năng mà tôi tin rằng sẽ giải quyết được bài toán này tốt hơn so với EA và cả MFEA-I.