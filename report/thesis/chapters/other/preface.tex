Trong nhiều thập kỷ gần đây, tính toán tiến hóa là giải pháp tiên phong trong đó các thuật toán được lấy cảm hứng từ lý thuyết sinh học, đề xuất để giải quyết các vấn đề, nghiên cứu hoạt động trong thế giới thực. Ứng dụng các khái niệm sinh học như quần thể, biến dị và đấu tranh sinh tồn để sinh ra các lời giải ngày càng tốt hơn cho các bài toán. Từ các phương pháp này đã sinh ra các lớp thuật toán được phân chia theo kỹ thuật sử dụng như thuật toán di truyền (genetic programing - gp), tối ưu bày đàn (particle swarm optimization - pso), và chiến lược tiến hóa (evolution strategy - es). Tuy nhiên các giải thuật này thông thường mới được dùng chỉ để giải các bài toán độc lập, đơn lẻ. Cho đến những năm gần đây, sự ưu việt của tiến ưu hóa đa nhiệm (multitfactorial evolutionary optimization) đã thu hút sự quan tâm đáng kể của các nhà nghiên cứu thuật toán tiến hóa. Một trong những điểm chính khiến tiến hóa đa nhiệm trở nên phổ biến để giải quyết bài toán tối ưu vì nó có khả năng tận dụng hiệu quả các kết quả tối ưu hóa giữa những bài toán tương tự, có liên quan đến nhau. Thông qua một biểu diễn chung của các bài toán, tiến hóa đa nhiệm sẽ ngầm kết hợp các nghiệm của từng bài toán để đưa ra lời giải tốt hơn, tăng tốc độ hội tụ trên từng tác vụ.

Trong đó, có nhiều nỗ lực nghiên cứu áp dụng tiến hóa đa nhiệm vào huấn luyện mạng nơ-ron thần kinh
nhân tạo (ANN). Các kết quả thực nghiệm đã thể hiện tiến hóa đa nhiệm đưa ra hiệu suất cao hơn, lỗi thấp hơn trong cùng một thời gian tính toán so với các thuật toán tối ưu đơn nhiệm cổ điển. Từ trước đến nay trong việc huấn luyện mạng Nơ-Ron thường dựa vào các thuật toán dựa trên sự tăng, giảm của đạo hàm (gradient based argorithm). Tuy nhiên, các phương pháp dạng này đang ngày càng thể hiện những hạn chế đặc biệt là trong các bài toán học tăng cường. Đó cũng là thời điểm các nhóm nghiên cứu nhận ra với những tiến bộ gần đây của lớp thuật toán tiến hóa. Các khó khăn trước khi với những giải thuật dựa trên đạo hàm có thể được giải quyết. Các nhóm nghiên cứu nổi bật có thể kể đến như OpenAI, Google Brain, Uber vv... 




% Bên cạnh đó các nhóm nghiên cứu hàng đầu như Deep Mind và OpenAI đã áp dụng thuật toán tiến hóa trong một lĩnh vực khác của trí tuệ nhân tạo đó là học củng cố (Reinforcement Learning). Trong học củng cố hàm mục tiêu là tổng điểm thưởng mà nhân vật nhận được từ môi trường thông qua số hành động nhất định. Tuy nhiên hàm này hoàn toàn dựa vào sự biến đổi chưa biết trước của môi trường, do đó việc xác định chính xác gradient của bài toán sẽ có nhiều nhiễu và khó thu được kết quả. Bởi vậy những thuật toán tối ưu hộp đen giống như thuật toán tiến hóa có khả năng áp dụng và đạt hiệu quả tốt. Khá nhiều ứng dụng có thể kể ra như Tự động hóa Robot, Trò chơi AI (nổi tiếng như Alphago) hoặc phân tích trao đổi tài chính vv.. Thực tế trong học tăng cường, nếu môi trường thay đổi một chút trong tham số môi trường như trọng lực, áp suất hoặc một số trò chơi sẽ thay đổi trong cài đặt. Sẽ là lãng phí khi giải quyết vấn đề này một cách cô lập với thuật toán tiến hóa thông thường bởi mỗi bước để tiến tới cách chơi (policy) tốt hơn trong một nhiệm vụ sẽ ảnh hưởng đến những nhiệm vụ liên quan. Điều này dẫn tới suy nghĩ tự nhiên là có thể áp dụng tiến hóa đa nhiệm để giải quyết nhiều bài toán học tăng cường có liên quan đồng thời.

Do đó, đồ án này đề xuất các giải thuật áp dụng sức mạnh của tiến hóa đa nhiệm đặc biệt là MFEA-II - thuật toán tiến hóa đa nhiệm mới nhất để huấn luyện nhiều mạng nơ-ron đồng thời. Đồ án sẽ cung cấp các nền tảng cơ bản, và thuật toán liên quan đến phương pháp đề xuất. Cùng với đó là các kết quả thực nghiệm kiểm tra mức độ hiệu quả của cách tiếp cận đã đề xuất so với các thuật toán tiến hóa thông thường, thuật toán tiến hóa đa nhiệm trước đây trên các bộ dữ liệu khác nhau. Đặc biệt, đồ án cũng đề xuất phương pháp áp dụng MFEA-II để huấn luyện nhiều mô hình học tăng cường đồng thời. 

Tôi tin rằng đồ án sẽ góp phần nào đó vào sự phát triển, tiên phong của thuật toán tiến hóa trong việc giải quyết vấn đề đã đề cập ở trên.

