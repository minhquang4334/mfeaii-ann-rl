@book{jansen2015analyzing,
 author = {Jansen, Thomas},
 title = {Analyzing Evolutionary Algorithms},
 year = {2015},
 isbn = {3642436013, 9783642436017},
 publisher = {Springer Publishing Company, Incorporated},
} 

@article{deb1995simulated,
  title={Simulated binary crossover for continuous search space},
  author={Deb, Kalyanmoy and Agrawal, Ram Bhushan and others},
  journal={Complex systems},
  volume={9},
  number={2},
  pages={115--148},
  year={1995},
  publisher={Citeseer}
}

@article{ong2016evolutionary,
  title={Evolutionary multitasking: A computer science view of cognitive multitasking},
  author={Ong, Yew-Soon and Gupta, Abhishek},
  journal={Cognitive Computation},
  volume={8},
  number={2},
  pages={125--142},
  year={2016},
  publisher={Springer}
}
@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}
@inproceedings{hershey2007approximating,
  title={Approximating the Kullback Leibler divergence between Gaussian mixture models},
  author={Hershey, John R and Olsen, Peder A},
  booktitle={2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP'07},
  volume={4},
  pages={IV--317},
  year={2007},
  organization={IEEE}
}

@article{white1982maximum,
  title={Maximum likelihood estimation of misspecified models},
  author={White, Halbert},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1--25},
  year={1982},
  publisher={JSTOR}
}

@article{stephen1990perceptron,
  title={Perceptron-based learning algorithms},
  author={Stephen, I},
  journal={IEEE Transactions on neural networks},
  volume={50},
  number={2},
  pages={179},
  year={1990}
}
@book{fine2006feedforward,
  title={Feedforward neural network methodology},
  author={Fine, Terrence L},
  year={2006},
  publisher={Springer Science \& Business Media}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{floreano2008neuroevolution,
  title={Neuroevolution: from architectures to learning},
  author={Floreano, Dario and D{\"u}rr, Peter and Mattiussi, Claudio},
  journal={Evolutionary intelligence},
  volume={1},
  number={1},
  pages={47--62},
  year={2008},
  publisher={Springer}
}
@book{hassoun1995fundamentals,
  title={Fundamentals of artificial neural networks},
  author={Hassoun, Mohamad H and others},
  year={1995},
  publisher={MIT press}
}
@article{such2017deep,
  title={Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning},
  author={Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1712.06567},
  year={2017}
}

@article{nqtuan,
  title={Evolutionary multi-task learning for modular training of multi-layers feedforward neural networks},
  author={Tuan, Nguyen Quoc, and Thanh, Le Tien},
  journal={School of Information and Communication Technology, Hanoi University of Science and Technology,}
}

@article{gupta2017insights,
  title={Insights on transfer optimization: Because experience is the best teacher},
  author={Gupta, Abhishek and Ong, Yew-Soon and Feng, Liang},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume={2},
  number={1},
  pages={51--64},
  year={2017},
  publisher={IEEE}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@inproceedings{eldan2016power,
  title={The power of depth for feedforward neural networks},
  author={Eldan, Ronen and Shamir, Ohad},
  booktitle={Conference on learning theory},
  pages={907--940},
  year={2016}
}
@inproceedings{kawaguchi2016deep,
  title={Deep learning without poor local minima},
  author={Kawaguchi, Kenji},
  booktitle={Advances in neural information processing systems},
  pages={586--594},
  year={2016}
}
@incollection{miikkulainen2019evolving,
  title={Evolving deep neural networks},
  author={Miikkulainen, Risto and Liang, Jason and Meyerson, Elliot and Rawal, Aditya and Fink, Daniel and Francon, Olivier and Raju, Bala and Shahrzad, Hormoz and Navruzyan, Arshak and Duffy, Nigel and others},
  booktitle={Artificial Intelligence in the Age of Neural Networks and Brain Computing},
  pages={293--312},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{wong2018transfer,
  title={Transfer learning with neural automl},
  author={Wong, Catherine and Houlsby, Neil and Lu, Yifeng and Gesmundo, Andrea},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8356--8365},
  year={2018}
}
@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@article{whitley1990genetic,
  title={Genetic algorithms and neural networks: Optimizing connections and connectivity},
  author={Whitley, Darrell and Starkweather, Timothy and Bogart, Christopher},
  journal={Parallel computing},
  volume={14},
  number={3},
  pages={347--361},
  year={1990},
  publisher={North-Holland}
}

@article{yao1999evolutionary,
  title={Evolutionary programming made faster},
  author={Yao, Xin and Liu, Yong and Lin, Guangming},
  journal={IEEE Transactions on Evolutionary computation},
  volume={3},
  number={2},
  pages={82--102},
  year={1999},
  publisher={IEEE}
}


@article{nesterov2013gradient,
  title={Gradient methods for minimizing composite functions},
  author={Nesterov, Yu},
  journal={Mathematical Programming},
  volume={140},
  number={1},
  pages={125--161},
  year={2013},
  publisher={Springer}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2009},
  publisher={IEEE}
}

@inproceedings{rasmussen2000infinite,
  title={The infinite Gaussian mixture model},
  author={Rasmussen, Carl Edward},
  booktitle={Advances in neural information processing systems},
  pages={554--560},
  year={2000}
}

@article{bali2019multifactorial,
  title={Multifactorial evolutionary algorithm with online transfer parameter estimation: MFEA-II},
  author={Bali, Kavitesh Kumar and Ong, Yew-Soon and Gupta, Abhishek and Tan, Puay Siew},
  journal={IEEE Transactions on Evolutionary Computation},
  year={2019},
  publisher={IEEE}
}

@book{darwin1859on,
  added-at = {2008-05-27T04:02:47.000+0200},
  address = {London},
  author = {Darwin, Charles},
  biburl = {https://www.bibsonomy.org/bibtex/2d70d713c717fb28384fb073c9f6dfbc2/neilernst},
  citeulike-article-id = {2376343},
  interhash = {c738acbb887362be5b0e6abc51be42d3},
  intrahash = {d70d713c717fb28384fb073c9f6dfbc2},
  keywords = {evolution},
  note = { or the Preservation of Favored Races in the Struggle for Life},
  priority = {2},
  publisher = {Murray},
  timestamp = {2008-05-27T04:02:47.000+0200},
  title = {On the Origin of Species by Means of Natural Selection},
  year = 1859
}

@INPROCEEDINGS{glorot2010understanding,
    author = {Xavier Glorot and Yoshua Bengio},
    title = {Understanding the difficulty of training deep feedforward neural networks},
    booktitle = {In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATSâ€™10). Society for Artificial Intelligence and Statistics},
    year = {2010}
}

@book{holland1992adaptation,
 author = {Holland, John H.},
 title = {Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control and Artificial Intelligence},
 year = {1992},
 isbn = {0262082136},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@book{schwefel1993evolution,
 author = {Schwefel, Hans-Paul Paul},
 title = {Evolution and Optimum Seeking: The Sixth Generation},
 year = {1993},
 isbn = {0471571482},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
} 

@book{rechenberg1973evolutionsstrategie,
  added-at = {2009-12-14T10:56:13.000+0100},
  address = {Stuttgart-Bad Cannstatt},
  author = {Rechenberg, I.},
  biburl = {https://www.bibsonomy.org/bibtex/2f051691c05943d7b006e71b121b4e53e/danfunky},
  interhash = {6d03f730f6d48b8df5266c676e77cf2b},
  intrahash = {f051691c05943d7b006e71b121b4e53e},
  keywords = {computing evolutionary},
  number = 15,
  owner = {D047718},
  publisher = {Frommann-Holzboog},
  series = {Problemata},
  timestamp = {2009-12-14T10:56:19.000+0100},
  title = {Evolutionsstrategie : Optimierung technischer Systeme nach Prinzipien
	der biologischen Evolution},
  year = 1973
}

@book{fogel1966artificial,
  added-at = {2012-08-18T21:00:12.000+0200},
  author = {Fogel, L. J. and Owens, A. J. and Walsh, M. J.},
  biburl = {https://www.bibsonomy.org/bibtex/2fd8859897836915a3af1df03b91b506e/dalbem},
  groups = {public},
  interhash = {b00ad1a37b66d622871464122f835a33},
  intrahash = {fd8859897836915a3af1df03b91b506e},
  keywords = {},
  publisher = {John Wiley},
  timestamp = {2012-08-18T21:00:12.000+0200},
  title = {Artificial Intelligence through Simulated Evolution},
  username = {dalbem},
  year = 1966
}

@book{koza92genetic,
  added-at = {2008-02-26T11:58:58.000+0100},
  address = {Cambridge, MA},
  author = {Koza, J. R.},
  biburl = {https://www.bibsonomy.org/bibtex/2ed8a794bcfca92ea5af1617c5f499848/schaul},
  citeulike-article-id = {2377578},
  description = {idsia},
  interhash = {e8307fb6cf4ee27405142256d98c4c9e},
  intrahash = {ed8a794bcfca92ea5af1617c5f499848},
  keywords = {nn},
  priority = {2},
  publisher = {MIT Press},
  timestamp = {2008-02-26T12:04:15.000+0100},
  title = {Genetic Programming: {O}n the Programming of Computers by Means of Natural Selection},
  year = 1992
}

@ARTICLE{gupta2016multifactorial,
    author={A. {Gupta} and Y. {Ong} and L. {Feng}},
    journal={IEEE Transactions on Evolutionary Computation},
    title={Multifactorial Evolution: Toward Evolutionary Multitasking},
    year={2016},
    volume={20},
    number={3},
    pages={343-357},
    keywords={genetic algorithms;multifactorial evolution;evolutionary multitasking;evolutionary algorithms;single optimization problem;biocultural models;multifactorial inheritance;complex developmental trait transmission;genetic factors;cultural factors;cross-domain optimization platform;implicit genetic transfer;refined genetic material transfer;refined genetic material creation;complex optimization functions;Optimization;Genetics;Multitasking;Cultural differences;Sociology;Statistics;Evolutionary computation;Evolutionary Multitasking;Memetic Computation;Continuous Optimization;Discrete Optimization;Continuous optimization;discrete optimization;evolutionary multitasking;memetic computation},
    doi={10.1109/TEVC.2015.2458037},
    ISSN={1089-778X},
    month={June},
}

@Article{chandra2018evolutionary,
author="Chandra, Rohitash
and Gupta, Abhishek
and Ong, Yew-Soon
and Goh, Chi-Keong",
title="Evolutionary Multi-task Learning for Modular Knowledge Representation in Neural Networks",
journal="Neural Processing Letters",
year="2018",
month="Jun",
day="01",
volume="47",
number="3",
pages="993--1009",
abstract="The brain can be viewed as a complex modular structure with features of information processing through knowledge storage and retrieval. Modularity ensures that the knowledge is stored in a manner where any complications in certain modules do not affect the overall functionality of the brain. Although artificial neural networks have been very promising in prediction and recognition tasks, they are limited in terms of learning algorithms that can provide modularity in knowledge representation that could be helpful in using knowledge modules when needed. Multi-task learning enables learning algorithms to feature knowledge in general representation from several related tasks. There has not been much work done that incorporates multi-task learning for modular knowledge representation in neural networks. In this paper, we present multi-task learning for modular knowledge representation in neural networks via modular network topologies. In the proposed method, each task is defined by the selected regions in a network topology (module). Modular knowledge representation would be effective even if some of the neurons and connections are disrupted or removed from selected modules in the network. We demonstrate the effectiveness of the method using single hidden layer feedforward networks to learn selected n-bit parity problems of varying levels of difficulty. Furthermore, we apply the method to benchmark pattern classification problems. The simulation and experimental results, in general, show that the proposed method retains performance quality although the knowledge is represented as modules.",
issn="1573-773X",
doi="10.1007/s11063-017-9718-z",
url="https://doi.org/10.1007/s11063-017-9718-z"
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@ARTICLE{barto1983neuronlike,
author={A. G. {Barto} and R. S. {Sutton} and C. W. {Anderson}},
journal={IEEE Transactions on Systems, Man, and Cybernetics},
title={Neuronlike adaptive elements that can solve difficult learning control problems},
year={1983},
volume={SMC-13},
number={5},
pages={834-846},
keywords={adaptive control;learning systems;neural nets;neural nets;adaptive control;neuronlike adaptive elements;learning control problem;movable cart;associative search element;adaptive critic element;animal learning studies;Adaptive systems;Problem-solving;Training;Pattern recognition;Neurons;Supervised learning;Biological neural networks},
doi={10.1109/TSMC.1983.6313077},
ISSN={0018-9472},
month={Sep.},}

@book{sutton1998introduction,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@article{moriarty1999earl,
 author = {Moriarty, David E. and Schultz, Alan C. and Grefenstette, John J.},
 title = {Evolutionary Algorithms for Reinforcement Learning},
 journal = {J. Artif. Int. Res.},
 issue_date = {July 1999},
 volume = {11},
 number = {1},
 month = jul,
 year = {1999},
 issn = {1076-9757},
 pages = {241--276},
 numpages = {36},
 url = {http://dl.acm.org/citation.cfm?id=3013545.3013551},
 acmid = {3013551},
 publisher = {AI Access Foundation},
 address = {USA},
}

@article{yao1999evolving,
  title={Evolving artificial neural networks},
  author={Yao, Xin},
  journal={Proceedings of the IEEE},
  volume={87},
  number={9},
  pages={1423--1447},
  year={1999},
  publisher={IEEE}
}

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@inproceedings{lehman2018more,
  title={ES is more than just a traditional finite-difference approximator},
  author={Lehman, Joel and Chen, Jay and Clune, Jeff and Stanley, Kenneth O},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={450--457},
  year={2018},
  organization={ACM}
}

@article{such2017deep,
  title={Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning},
  author={Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1712.06567},
  year={2017}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{gupta2016measuring,
  title={Measuring complementarity between function landscapes in evolutionary multitasking},
  author={Gupta, A and Ong, YS and Da, B and Feng, L and Handoko, S},
  booktitle={2016 IEEE Congress on Evolutionary Computation, accepted},
  year={2016}
}

@inproceedings{tang2017evolutionary,
  title={Evolutionary multi-task learning for modular extremal learning machine},
  author={Tang, Zedong and Gong, Maoguo and Zhang, Mingyang},
  booktitle={2017 IEEE Congress on Evolutionary Computation (CEC)},
  pages={474--479},
  year={2017},
  organization={IEEE}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{ong2016evolutionary,
  title={Evolutionary multitasking: a computer science view of cognitive multitasking},
  author={Ong, Yew-Soon and Gupta, Abhishek},
  journal={Cognitive Computation},
  volume={8},
  number={2},
  pages={125--142},
  year={2016},
  publisher={Springer}
}

@book{boyd2004cvx,
 author = {Boyd, Stephen and Vandenberghe, Lieven},
 title = {Convex Optimization},
 year = {2004},
 isbn = {0521833787},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 

@TECHREPORT{deb94simulated,
    author = {Kalyanmoy Deb and Ram Bhushan Agrawal},
    title = {Simulated Binary Crossover for Continuous Search Space},
    institution = {},
    year = {1994}
}

@book{russell2009artificial,
 author = {Russell, Stuart and Norvig, Peter},
 title = {Artificial Intelligence: A Modern Approach},
 year = {2009},
 isbn = {0136042597, 9780136042594},
 edition = {3rd},
 publisher = {Prentice Hall Press},
 address = {Upper Saddle River, NJ, USA},
} 

@ARTICLE{jain96artificial,
    author = {Anil K. Jain and Jianchang Mao and K. Mohiuddin},
    title = {Artificial Neural Networks: A Tutorial},
    journal = {IEEE Computer},
    year = {1996},
    volume = {29},
    pages = {31--44}
}

@article{caruana1997multitask,
 author = {Caruana, Rich},
 title = {Multitask Learning},
 journal = {Mach. Learn.},
 issue_date = {July 1997},
 volume = {28},
 number = {1},
 month = jul,
 year = {1997},
 issn = {0885-6125},
 pages = {41--75},
 numpages = {35},
 url = {https://doi.org/10.1023/A:1007379606734},
 doi = {10.1023/A:1007379606734},
 acmid = {262872},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {backpropagation, generalization, inductive transfer, k-nearest neighbor, kernel regression, multitask learning, parallel transfer, supervised learning},
} 

@incollection{yosinki2014how,
title = {How transferable are features in deep neural networks?},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {3320--3328},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf}
}